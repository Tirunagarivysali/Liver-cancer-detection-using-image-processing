{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/img.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4553892c9844>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/img.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\js\\opencv\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/img.jpg'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "threshold_values = {}\n",
    "h = [1]\n",
    "\n",
    "\n",
    "def Hist(img):\n",
    "   row, col = img.shape \n",
    "   print(row,col)  #This comes out to be 311 X 569.\n",
    "   y = np.zeros(256)\n",
    "   for i in range(0,row):\n",
    "      for j in range(0,col):\n",
    "         y[img[i,j]] += 1\n",
    "   x = np.arange(0,256)\n",
    "   plt.bar(x, y, color='b', width=5, align='center', alpha=0.25)\n",
    "   plt.show()\n",
    "   return y\n",
    "\n",
    "\n",
    "def regenerate_img(img, threshold):\n",
    "    row, col = img.shape \n",
    "    y = np.zeros((row, col))\n",
    "    for i in range(0,row):\n",
    "        for j in range(0,col):\n",
    "            if img[i,j] >= threshold:\n",
    "                y[i,j] = 255\n",
    "            else:\n",
    "                y[i,j] = 0\n",
    "    return y\n",
    "\n",
    "\n",
    "   \n",
    "def countPixel(h):\n",
    "    cnt = 0\n",
    "    for i in range(0, len(h)):\n",
    "        if h[i]>0:\n",
    "           cnt += h[i]\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def wieght(s, e):\n",
    "    w = 0\n",
    "    for i in range(s, e):\n",
    "        w += h[i]\n",
    "    return w\n",
    "\n",
    "\n",
    "def mean(s, e):\n",
    "    m = 0\n",
    "    w = wieght(s, e)\n",
    "    for i in range(s, e):\n",
    "        m += h[i] * i\n",
    "    \n",
    "    return m/float(w)\n",
    "\n",
    "\n",
    "def variance(s, e):\n",
    "    v = 0\n",
    "    m = mean(s, e)\n",
    "    w = wieght(s, e)\n",
    "    for i in range(s, e):\n",
    "        v += ((i - m) **2) * h[i]\n",
    "    v /= w\n",
    "    return v\n",
    "            \n",
    "\n",
    "def threshold(h):\n",
    "    cnt = countPixel(h)\n",
    "    for i in range(1, len(h)):\n",
    "        vb = variance(0, i)\n",
    "        wb = wieght(0, i) / float(cnt)\n",
    "        mb = mean(0, i)\n",
    "        \n",
    "        vf = variance(i, len(h))\n",
    "        wf = wieght(i, len(h)) / float(cnt)\n",
    "        mf = mean(i, len(h))\n",
    "        \n",
    "        V2w = wb * (vb) + wf * (vf)\n",
    "        V2b = wb * wf * (mb - mf)**2\n",
    "        \n",
    "        fw = open(\"trace.txt\", \"a\")\n",
    "        fw.write('T='+ str(i) + \"\\n\")\n",
    "\n",
    "        fw.write('Wb='+ str(wb) + \"\\n\")\n",
    "        fw.write('Mb='+ str(mb) + \"\\n\")\n",
    "        fw.write('Vb='+ str(vb) + \"\\n\")\n",
    "        \n",
    "        fw.write('Wf='+ str(wf) + \"\\n\")\n",
    "        fw.write('Mf='+ str(mf) + \"\\n\")\n",
    "        fw.write('Vf='+ str(vf) + \"\\n\")\n",
    "\n",
    "        fw.write('within class variance='+ str(V2w) + \"\\n\")\n",
    "        fw.write('between class variance=' + str(V2b) + \"\\n\")\n",
    "        fw.write(\"\\n\")\n",
    "        \n",
    "        if not math.isnan(V2w):\n",
    "            threshold_values[i] = V2w\n",
    "\n",
    "\n",
    "def get_optimal_threshold():\n",
    "    min_V2w = min(threshold_values.values())\n",
    "    optimal_threshold = [k for k, v in threshold_values.items() if v == min_V2w]\n",
    "    print('optimal threshold', optimal_threshold[0])\n",
    "    return optimal_threshold[0]\n",
    "\n",
    "\n",
    "image = Image.open('/content/img.jpg').convert(\"L\")\n",
    "img = np.asarray(image)\n",
    "\n",
    "h = Hist(img)\n",
    "threshold(h)\n",
    "op_thres = get_optimal_threshold()\n",
    "\n",
    "res = regenerate_img(img, op_thres)\n",
    "plt.imshow(res)\n",
    "plt.savefig(\"/content/otsu.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow as im\n",
    "\n",
    "\n",
    "\n",
    "# This is simply converting it to grayscale and applying the Otsu's thresholding.\n",
    "img = cv.imread(\"/content/img.jpg\",1)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "th1 = 0\n",
    "th2 = 255\n",
    "ret,thresh = cv.threshold(gray,th1,th2,cv.THRESH_BINARY + cv.THRESH_OTSU)\n",
    "   \n",
    "    # noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "   \n",
    "    # sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "   \n",
    "    # Defining accuracuy\n",
    "acc = 0.01\n",
    "   \n",
    "    # Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "ret, sure_fg = cv.threshold(dist_transform,acc*dist_transform.max(),255,0)\n",
    "   \n",
    "    # Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)\n",
    "   \n",
    "    # Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    " \n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "   \n",
    "    # Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [0,0,255]\n",
    "   \n",
    "   \n",
    "cv.imwrite(\"content/segmentation.jpg\",img)\n",
    "im(img)\n",
    "   \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before starting we should know what is countour exactly.\n",
    "'''\n",
    "Contours can be explained simply as a curve joining all the continuous points (along the boundary),\n",
    " having same color or intensity. \n",
    " The contours are a useful tool for shape analysis and \n",
    " object detection and recognition. \n",
    " For better accuracy, use binary images.\n",
    "'''\n",
    "\n",
    "# import the necessary packages\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow as im\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "# \thelp=\"path to input image\")\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# # load the image and perform pyramid mean shift filtering\n",
    "# # to aid the thresholding step\n",
    "image = cv2.imread('/content/img.jpg')\n",
    "shifted = cv2.pyrMeanShiftFiltering(image, 21, 51)\n",
    "#cv2.imshow(\"Input\", shifted)\n",
    "\n",
    "# convert the mean shift image to grayscale, then apply\n",
    "# Otsu's thresholding\n",
    "gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255,\n",
    "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "im(thresh)\n",
    "\n",
    "# compute the exact Euclidean distance from every binary\n",
    "# pixel to the nearest zero pixel, then find peaks in this\n",
    "# distance map\n",
    "D = ndimage.distance_transform_edt(thresh)\n",
    "localMax = peak_local_max(D, indices=False, min_distance=20,\n",
    "\tlabels=thresh)\n",
    "\n",
    "# perform a connected component analysis on the local peaks,\n",
    "# using 8-connectivity, then appy the Watershed algorithm with active countors.\n",
    "markers = ndimage.label(localMax, structure=np.ones((3, 3)))[0]\n",
    "labels = watershed(-D, markers, mask=thresh)\n",
    "print(\"[INFO] {} unique segments found\".format(len(np.unique(labels)) - 1))\n",
    "\n",
    "# loop over the unique labels returned by the Watershed\n",
    "# algorithm\n",
    "for label in np.unique(labels):\n",
    "\t# if the label is zero, we are examining the 'background'\n",
    "\t# so simply ignore it\n",
    "\tif label == 0:\n",
    "\t\tcontinue\n",
    "\n",
    "\t# otherwise, allocate memory for the label region and draw\n",
    "\t# it on the mask\n",
    "\tmask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "\tmask[labels == label] = 255\n",
    "\n",
    "\t# detect contours in the mask and grab the largest one\n",
    "\tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tc = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "\t# draw a circle enclosing the object\n",
    "\t((x, y), r) = cv2.minEnclosingCircle(c)\n",
    "\tcv2.circle(image, (int(x), int(y)), int(r), (0, 255, 0), 2)\n",
    "\t# cv2.putText(image, \"#{}\".format(label), (int(x) - 10, int(y)),\n",
    "\t# \tcv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "# show the output image\n",
    "im(image)\n",
    "cv2.imwrite(\"content/contour.jpg\",image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice similarity score is 0.00019607138058098448\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "k=1\n",
    "\n",
    "# segmentation\n",
    "seg = Image.open('../Result/Test/segmentation.jpg').convert(\"L\")\n",
    "seg = np.asarray(seg)\n",
    " \n",
    "# ground truth\n",
    "gt = Image.open('../Dataset/Test/gt.jpg').convert(\"L\")\n",
    "gt = np.asarray(seg)\n",
    "\n",
    "dice = np.sum(seg[gt==k])*2.0 / (np.sum(seg) + np.sum(gt))\n",
    "\n",
    "print(\"Dice similarity score is {}\".format(dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice similarity score is 0.0002464599353843849\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "k=1\n",
    "\n",
    "# segmentation\n",
    "seg = Image.open('../Result/Test/contour.jpg').convert(\"L\")\n",
    "seg = np.asarray(seg)\n",
    " \n",
    "# ground truth\n",
    "gt = Image.open('../Dataset/Test/gt.jpg').convert(\"L\")\n",
    "gt = np.asarray(seg)\n",
    "\n",
    "dice = np.sum(seg[gt==k])*2.0 / (np.sum(seg) + np.sum(gt))\n",
    "\n",
    "print(\"Dice similarity score is {}\".format(dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
